{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "trasnformers.ipynb",
      "provenance": [],
      "collapsed_sections": [],
      "private_outputs": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "TPU"
  },
  "cells": [
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "RPJCdHDXAFxj"
      },
      "outputs": [],
      "source": [
        "#at first import the library\n",
        "import tensorflow as tf\n",
        "import matplotlib.pyplot as plt\n",
        "import numpy as np"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "image = tf.keras.preprocessing.image.load_img(\"portrait.jpg\" , target_size = (144,144))\n",
        "image"
      ],
      "metadata": {
        "id": "pjUa9jXxARDe"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "imageArray = tf.keras.preprocessing.image.img_to_array(image)\n",
        "print(imageArray.shape)"
      ],
      "metadata": {
        "id": "0wLTIuQ9B4ud"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#Because we need to have dimension in every patch so we add one column to our matrix\n",
        "imageArray = imageArray[tf.newaxis , ...]\n",
        "print(imageArray.shape)"
      ],
      "metadata": {
        "id": "YS4vcnDFCO5e"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#We need to make some patches\n",
        "patches = tf.image.extract_patches(imageArray , sizes = [1,16,16,1] , strides = [1,16,16,1], rates = [1,1,1,1], padding = \"VALID\" )\n",
        "print(patches.shape)"
      ],
      "metadata": {
        "id": "Ah7DIM78DIQ1"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#Flatten the patches\n",
        "patches = tf.reshape(patches , shape=(tf.shape(patches)[0] , -1 , 16*16*3))"
      ],
      "metadata": {
        "id": "Y_lb7ltbIJ15"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "print(patches.shape)\n"
      ],
      "metadata": {
        "id": "k_9AWPaUIsn3"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#Divide the image to some patches\n",
        "n = int(np.sqrt(patches.shape[1]))\n",
        "plt.figure(figsize=(n*n,1))\n",
        "for i, patch in enumerate(patches[0]):\n",
        "    ax = plt.subplot(1,n*n, i + 1)\n",
        "    patch_img = tf.reshape(patch, (16 , 16 , 3))\n",
        "    plt.imshow(patch_img.numpy().astype(\"uint8\"))\n",
        "    plt.axis(\"off\")\n"
      ],
      "metadata": {
        "id": "ZiFHvGI5I6AY"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#DEFINING A CLASS TO DO PATCH EMBEDDING AUTOMATICALLY\n",
        "class PatchEmbedding(tf.keras.layers.Layer):\n",
        "  def __init__(self, size , num_of_patches , projection_dim):\n",
        "    super().__init__()\n",
        "    self.size = size\n",
        "    #we add +1 because ClS has a position for himself\n",
        "    self.num_of_patches = num_of_patches + 1 \n",
        "    self.projection_dim = projection_dim\n",
        "    self.projection = tf.keras.layers.Dense(projection_dim)\n",
        "    self.clsToken = tf.Variable(tf.keras.initializers.GlorotNormal()(shape = (1,1,projection_dim)) , trainable = True)\n",
        "    self.positionalEmbedding = tf.keras.layers.Embedding(self.num_of_patches , projection_dim)\n",
        "\n",
        "\n",
        "  def call(self , inputs):\n",
        "    #extracting patches\n",
        "    patches = tf.image.extract_patches(inputs, sizes=[1 , self.size, self.size , 1] , strides = [1, self.size , self.size , 1] , rates = [1 , 1 , 1 , 1] , padding = \"VALID\")\n",
        "    #make 1D patches. we know that the image is color\n",
        "    #if we don't know, we can change the code to be dynamic!\n",
        "    patches = tf .reshape(patches , (tf.shape(inputs)[0] , -1 , self.size * self.size * 3))\n",
        "    #project the patches with \"tf.keras.layers.Dense\"\n",
        "    patches = self.projection(patches)\n",
        "     \n",
        "    clsToken = tf.repeat(self.clsToken , tf.shape (inputs)[0], 0)\n",
        "    patches = tf.concat((clsToken , patches ), axis = 1)\n",
        "    #making positions with range. self.num_of_patches is number of positions\n",
        "    #and the third input is our step\n",
        "    positions = tf.range(0 , self.num_of_patches , 1)[tf.newaxis , ...]\n",
        "    #adding positions to vectors\n",
        "    positionalEmbedding = self.positionalEmbedding(positions)\n",
        "    #print(posisionalEmbedding)\n",
        "    patches = patches + positionalEmbedding\n",
        "    return patches"
      ],
      "metadata": {
        "id": "wTP4O0ZKPXPE"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "embedding = PatchEmbedding(16,81,128)"
      ],
      "metadata": {
        "id": "iI_M6igoRIfm"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "result = embedding (tf.random.normal(shape = (32,144,144,3)))"
      ],
      "metadata": {
        "id": "Gg8UEUshWQ9D"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "print(result.shape)"
      ],
      "metadata": {
        "id": "j474GfhxWe2R"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#Transformer layer\n",
        "class TransformerLayer(tf.keras.layers.Layer):\n",
        "  def __init__ (self, d_model , heads , mlp_rate , dropout_rate = 0.1):\n",
        "     super().__init__()\n",
        "\n",
        "     self.layernorm_1 = tf.keras.layers.LayerNormalization(epsilon = 1e-6)\n",
        "     self.mha = tf.keras.layers.MultiHeadAttention(heads, d_model//heads , dropout = dropout_rate)\n",
        "      \n",
        "     self.layernorm_2 =tf.keras.layers.LayerNormalization(epsilon =1e-6)\n",
        "     self.mlp = tf.keras.Sequential([\n",
        "                                     tf.keras.layers.Dense(d_model * mlp_rate , activation = \"gelu\"), \n",
        "                                     tf.keras.layers.Dropout(dropout_rate),\n",
        "                                     tf.keras.layers.Dense(d_model , activation = \"gelu\"),\n",
        "                                     tf.keras.layers.Dropout(dropout_rate)\n",
        "      ])\n",
        "  def call(self, inputs, training = True):\n",
        "       out_1 = self.layernorm_1(inputs)\n",
        "       out_1 = self.mha(out_1, out_1, training = training)\n",
        "       out_1 = inputs + out_1\n",
        "\n",
        "       out_2 = self.layernorm_2(out_1)\n",
        "       out_2 = self.mlp(out_2, training = training)\n",
        "       out_2 = out_1 + out_2\n",
        "       return out_2"
      ],
      "metadata": {
        "id": "jFO4dxVKb9ET"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#make a transformer encoder with transformer layers\n",
        "class TransformerEncoder(tf.keras.layers.Layer):\n",
        "  def __init__ (self, d_model , heads , mlp_rate , num_layers=1  , dropout_rate=0.1 ):\n",
        "     super().__init__()\n",
        "     self.encoders = [TransformerLayer(d_model , heads , mlp_rate , dropout_rate) for _ in range(num_layers)]\n",
        " \n",
        "  def call(self , inputs , training = True):\n",
        "    x = inputs\n",
        "\n",
        "    for layer in self.encoders:\n",
        "      x = layer(x, training = training)\n",
        "    return x"
      ],
      "metadata": {
        "id": "NTkGn4eX4acq"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "class ViT(tf.keras.Model):\n",
        "  def __init__(self, num_classes, patch_size, num_of_patches, d_model , heads , num_layers , mlp_rate , dropout_rate=0.1):\n",
        "     super().__init__()\n",
        "\n",
        "     self.patchEmbedding = PatchEmbedding(patch_size , num_of_patches , d_model)\n",
        "     self.encoder = TransformerEncoder(d_model , heads , mlp_rate ,num_layers, dropout_rate)\n",
        "     self.prediction = tf.keras.Sequential([\n",
        "                                           tf.keras.layers.Dropout(0.3),\n",
        "                                           tf.keras.layers.Dense(mlp_rate*d_model , activation = \"gelu\"), \n",
        "                                           tf.keras.layers.Dropout(0.3),\n",
        "                                           tf.keras.layers.Dense(num_classes , activation = \"softmax\")\n",
        "                                            \n",
        "     ])\n",
        "  \n",
        "\n",
        "\n",
        "\n",
        "  def call(self, inputs , training = True):\n",
        "     patches = self.patchEmbedding(inputs)\n",
        "     #print(patches)\n",
        "     encoderResult = self.encoder(patches , training = training)\n",
        "\n",
        "     clsResult = encoderResult[:,0,:]\n",
        "\n",
        "     prediction = self.prediction(clsResult,training=training)\n",
        "     return prediction"
      ],
      "metadata": {
        "id": "dBP2oerF9UGi"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "#inja error mide!!!!!!!\n",
        "vitClassifier = ViT(\n",
        "                    100,\n",
        "                    16,\n",
        "                    81,\n",
        "                    128,\n",
        "                    2,\n",
        "                    4,\n",
        "                    2,\n",
        "                    0.1)"
      ],
      "metadata": {
        "id": "gIeDDw40zCBS"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "vitClassifier(tf.random.normal(shape = (32 , 144 , 144 , 3)))"
      ],
      "metadata": {
        "id": "Fr4-rtcUzXs-"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "(x_train , y_train) , (x_test , y_test) = tf.keras.datasets.cifar10.load_data()"
      ],
      "metadata": {
        "id": "7hFQ5TT4VMwX"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "print(x_train.shape)"
      ],
      "metadata": {
        "id": "YaiaMEn0Vgcf"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "preprocessingModel = tf.keras.Sequential([\n",
        "                                          tf.keras.layers.Normalization(),\n",
        "                                          tf.keras.layers.Resizing(72,72),\n",
        "\n",
        "])\n",
        "preprocessingModel.layers[0].adapt(x_train)\n",
        "augmentationModel = tf.keras.Sequential([\n",
        "                                         tf.keras.layers.experimental.preprocessing.RandomFlip(\"horizontal\"),\n",
        "                                         tf.keras.layers.experimental.preprocessing.RandomRotation(factor = 0.2),\n",
        "                                         tf.keras.layers.experimental.preprocessing.RandomZoom(width_factor = 0.2, height_factor =0.2 ),\n",
        "\n",
        "\n",
        "                                         \n",
        "])"
      ],
      "metadata": {
        "id": "JyS7McVYVqcW"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from tensorflow.python.data.ops.dataset_ops import AUTOTUNE\n",
        "def convert_to_dataset(data, batch_size, shuffle = False, augment = False):\n",
        "  dataset = tf.data.Dataset.from_tensor_slices(data)\n",
        "  dataset = dataset.map(lambda x, y:(preprocessingModel(x)[0],y), num_parallel_calls=tf.data.AUTOTUNE)\n",
        "  if shuffle:\n",
        "     dataset = dataset.shuffle(len(dataset))\n",
        "  dataset = dataset.batch(batch_size,drop_remainder= True)\n",
        "  if augment:\n",
        "    dataset = dataset.map(lambda x, y:(augmentationModel(x , training = True),y), num_parallel_calls=tf.data.AUTOTUNE)\n",
        "  return dataset.prefetch(tf.data.AUTOTUNE)"
      ],
      "metadata": {
        "id": "hk5LMGCTW9jg"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "trainingData = convert_to_dataset((x_train , y_train) , 1024 , shuffle = True , augment=True)\n",
        "valData = convert_to_dataset ((x_test , y_test) , 1024 , shuffle = False , augment= False)"
      ],
      "metadata": {
        "id": "p-VwghUyZKPO"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#print(trainingData)\n",
        "#print(valData)"
      ],
      "metadata": {
        "id": "WuZFW11fZAFw"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "resolver = tf.distribute.cluster_resolver.TPUClusterResolver(tpu='')\n",
        "tf.config.experimental_connect_to_cluster(resolver)\n",
        "# This is the TPU initialization code that has to be at the beginning.\n",
        "tf.tpu.experimental.initialize_tpu_system(resolver)\n",
        "print(\"All devices: \", tf.config.list_logical_devices('TPU'))"
      ],
      "metadata": {
        "id": "dmzDM79aaQT4"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "strategy = tf.distribute.TPUStrategy(resolver)"
      ],
      "metadata": {
        "id": "bLE9JYxYbVvF"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "trainingDATA = convert_to_dataset((x_train , y_train) , 1024 , shuffle = True , augment=True)\n",
        "valData = convert_to_dataset ((x_test , y_test) , 1024 , shuffle = False , augment= False)\n"
      ],
      "metadata": {
        "id": "X_qDv1X4bg-u"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        ""
      ],
      "metadata": {
        "id": "MFZfhCawy3QV"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from os import name\n",
        "with strategy.scope():\n",
        "  vitClassifier = ViT(\n",
        "                      10, \n",
        "                       6, \n",
        "                      (72//6)**2, \n",
        "                      128, \n",
        "                      2,\n",
        "                      4,\n",
        "                      2,\n",
        "                      0.1\n",
        "      \n",
        "  )\n",
        "  vitClassifier.compile(\n",
        "      loss = tf.keras.losses.SparseCategoricalCrossentropy(),\n",
        "      optimizer = \"adam\",\n",
        "      metrics = [\n",
        "                 tf.keras.metrics.SparseCategoricalAccuracy(name = \"accuracy\"),\n",
        "                 tf.keras.metrics.SparseTopKCategoricalAccuracy(name = \"top_5_accuracy\")\n",
        "\n",
        "      ]\n",
        "  )"
      ],
      "metadata": {
        "id": "F7cxBM0Nbo3V"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "vitClassifier.fit(trainingData, batch_size = 1024, validation_data = valData , epochs = 20)"
      ],
      "metadata": {
        "id": "Bj-JgBHm43lI"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}